# Название

- [Название](#название)
  - [Постановка задачи](#постановка-задачи)
  - [Финальное решение](#финальное-решение)
    - [Решение влоб — сatboost](#решение-влоб--сatboost)
      - [Метрики на валидации](#метрики-на-валидации)
      - [Модель](#модель)
    - [Решение сложное](#решение-сложное)
      - [Метрики на валидации](#метрики-на-валидации-1)
      - [Модель](#модель-1)
  - [Как я пришел к этому](#как-я-пришел-к-этому)
    - [Данные](#данные)
    - [Эксперименты](#эксперименты)
      - [Устойчивость к NaN в test](#устойчивость-к-nan-в-test)


## Постановка задачи
* В файле `problem_train.csv` в каждой строке содержится информация об объекте
с уникальным идентификатором, заданным в столбце `id`.

* В файле `problem_labels.csv` для каждого `id` из файла `problem_train.csv` приведена информация о
принадлежности к 14 категориям.

* В файле `problem_test.csv` дана информация об объектах, аналогичная содержащейся в файле
`problem_train.csv`.

* Используя `problem_train.csv` и `problem_labels.csv` в качестве данных для обучения, постройте файл
`problem_test_labels.csv`, в котором для каждого объекта из файла `problem_test.csv` укажите
вероятность его принадлежности к каждой из 14 рассматриваемых категорий.

* Для оценки качества полученного результата будет использоваться метрика `LogLoss`. По каждой из 14 
категорий метрика считается независимо, затем берется среднее арифметическое значений метрик,
полученных для категорий.

* Пожалуйста, предоставьте краткое описание пути поиска решения и код, использованный для получения
результата.


## Финальное решение

### Решение влоб — сatboost

#### Метрики на валидации

| label     | score |
| --------- | ----- |
| mean      | 0.26  |
| service_a | 0.37  |
| service_b | 0.49  |
| service_c | 0.51  |
| service_d | 0.03  |
| service_e | 0.15  |
| service_f | 0.06  |
| service_g | 0.20  |
| service_h | 0.43  |
| service_i | 0.04  |
| service_j | 0.36  |
| service_k | 0.45  |
| service_l | 0.11  |
| service_m | 0.10  |
| service_n | 0.33  |

#### Модель
catboost

### Решение сложное

#### Метрики на валидации

| label     | score |
| --------- | ----- |
| mean      | 0.28  |
| service_a | 0.37  |
| service_b | 0.49  |
| service_c | 0.51  |
| service_d | 0.03  |
| service_e | 0.18  |
| service_f | 0.05  |
| service_g | 0.16  |
| service_h | 0.47  |
| service_i | 0.06  |
| service_j | 0.35  |
| service_k | 0.45  |
| service_l | 0.22  |
| service_m | 0.19  |
| service_n | 0.33  |

#### Модель
logreg go br....


## Как я пришел к этому
### Данные
Поступившие данные были достаточно загадочны. Подробно я их анализирую в [ноутбуке EDA](./notebooks/001%20-%20eda.ipynb).

У нас есть 8000 семплов и 1379 колонок. Из них 1000 категориальных, как минимум 9 ordinal (1 2 3 ...) и 345 float.

```python
>>> train_df.dtypes.value_counts()

object     1025
float64     345
int64         9
```

Названия колонок зашифрованы — `c_1375`, `n_0005`, `o_0233`. Есть одна названная `release`. Вместе с названиями лейблов `service_4` это наводит меня на мысль о том, что домен - это набор сервисов в инфраструктуре, и эти сервисы могут релизиться. Возможно, мы определяем, какие сервисы в данный момент сбоят исходя из каких-то продовых метрик.

```python
>>> train_df.columns.to_series().apply(lambda name: name[:2]).value_counts()

c_    1050
o_     211
n_     116
id       1
re       1
```

При этом данные по большей части состоят из NaN-ов. 768 (больше половины) колонок состоят на 95 % из NaN-ов.

```python
>>> len(desc.loc["count"][desc.loc["count"] < 400])

768
```

Есть фичи, полностью NaN на трейне.
```python
>>> len(desc.loc["count"][desc.loc["count"] == 0].index)

30
```

Также есть фичи, которые принимают на всей трейн выборке одно значение — 1.
```python
>>> len(desc.loc["count"][desc.loc["unique"] == 1].index)

102
```

Когда я обнаружил такую разреженность в данных, решил строить бейзлан на хорошо определенных фичах.
В качестве критерия взял, что фича должна быть определена на >= 7000/8000 семплов.
Можно было взять и поменьше, но я не был уверен, как повлияет бо́льшее количество imputed данных на предсказания.

![feature counts](./img/feature_counts.png)

```python
>>> train_counts = train_df.describe(include="all").loc["count"]
>>> len(train_counts[train_counts > 7000])

90
```

Среди этих фичей я обнаружил 6 фичей, у которых было одно уникальное значение, т.е. они не несут никакой полезной нагрузки.
```python
>>> train_df[["n_0047", "n_0050", "n_0052", "n_0061", "n_0075", "n_0091"]].apply(pd.value_counts)

	n_0047	n_0050	n_0052	n_0061	n_0075	n_0091
1	8000	8000	8000	8000	8000	8000
```
---

У многих лейблов, как мы любим, сильный дисбаланс классов: `d, e, f, g, i, j, l, m`

```python
>>> train_labels_df.apply(lambda x: pd.value_counts(x, normalize=True)).round(2).T

            0	    1
service_a	0.53	0.47
service_b	0.67	0.33
service_c	0.74	0.26
service_d	0.98	0.02
service_e	0.95	0.05
service_f	0.97	0.03
service_g	0.95	0.05
service_h	0.70	0.30
service_i	0.98	0.02
service_j	0.15	0.85
service_k	0.22	0.78
service_l	0.89	0.11
service_m	0.91	0.09
service_n	0.82	0.18
```

Я заметил, что некоторые лейблы сильно скоррелированы друг с другом (например, `pearson(i-m)` = 0.8), но дальше этот вопрос не исследовал.

![labels correlation](./img/labels_correlaion.png)

---
У тестовых данных фичи те же самые, что и у трейновых.
```python
>>> len(train_df.columns.intersection(test_df.columns))

1379
```

В тесте также присутствовали полностью NaN колонки.
```python
>>> len(test_desc.loc["count"][test_desc.loc["count"] == 0].index)

179
```
Я решил не удалять их из трейн данных, потому что в разное время на проде у нас разные колонки могут NaN-иться,
так что модель должна быть устойчива к такому поведению. Я немного [поисследовал](#устойчивость-к-NaN-в-test)) это свойство моей модели.

---

### Эксперименты



#### Устойчивость к NaN в test
В [ноутбуке 6](./notebooks/006%20-%20try%20to%20use%20more%20columns.ipynb) я попробовал исследовать,
как модель будет себя вести, если какие-то из используемых ею колонок внезапно станут nan-ам (например, сдохнет сервис, которых посылают данную фичу).
Дизайн: обучаем на всех фичах, в валидации маскируем 10% случайно выбранных фичей.
Результат: большинство маскировок незначительно влияло на средний logloss (0 - 0.1).
Возможно, это потому что либо большинство фичей бесполезных, либо потому что моя модель делает decision только лишь по некоторым из них.
При этом я заметил, что маскировка фичи `c_1259` стабильно занижает скор,
особенно на `service_a` (+ 1.4), а также на других: (`service_b` + 0.26, `service_h` + 0.10, `service_{c,d}` + 0.04).

Я посмотрел на корреляцию между `service_a` и 84 используемыми фичами, фича `c_1259` далеко не самая высоко коррелирующая.
Почему ее NaN-изация так влияет, не знаю.